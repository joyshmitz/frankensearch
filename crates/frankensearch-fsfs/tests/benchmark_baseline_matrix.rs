use std::collections::BTreeSet;
use std::fs;
use std::io::Write;
use std::path::{Path, PathBuf};
use std::process::Command;

use serde::{Deserialize, Serialize};
use tempfile::TempDir;

const GOLDEN_SCHEMA_VERSION: &str = "fsfs-benchmark-golden-v1";
const ARTIFACT_SCHEMA_VERSION: &str = "fsfs-benchmark-artifact-v1";
const MATRIX_VERSION: &str = "fsfs-benchmark-matrix-v1";
const GOLDEN_PROFILES: [&str; 3] = ["tiny", "small", "medium"];

#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
enum BenchmarkPath {
    Crawl,
    Index,
    Query,
    Tui,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
enum ComparatorMetric {
    P95LatencyMs,
    ThroughputPerSecond,
    FrameBudgetMs,
}

#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
struct ComparatorDefinition {
    path: BenchmarkPath,
    metric: ComparatorMetric,
    baseline_key: String,
    max_regression_pct: f32,
}

#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
struct BenchmarkCase {
    path: BenchmarkPath,
    dataset_profile: String,
    warmup_iterations: u32,
    measured_iterations: u32,
}

#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
struct BenchmarkMatrix {
    schema_version: String,
    matrix_version: String,
    cases: Vec<BenchmarkCase>,
    comparators: Vec<ComparatorDefinition>,
}

#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
struct CorpusStats {
    files: u64,
    tokens: u64,
    lines: u64,
    bytes: u64,
}

#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
struct WorkloadStats {
    crawl_events: u64,
    index_documents: u64,
    query_cases: u64,
    tui_interactions: u64,
}

#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
struct BaselineP95Ms {
    crawl: u64,
    index: u64,
    query: u64,
    tui_frame: u64,
}

#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
struct GoldenDataset {
    schema_version: String,
    dataset_version: String,
    profile: String,
    corpus: CorpusStats,
    workload: WorkloadStats,
    baseline_p95_ms: BaselineP95Ms,
    notes: Vec<String>,
}

#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
struct BenchmarkArtifactManifest {
    schema_version: String,
    matrix_version: String,
    dataset_profile: String,
    dataset_version: String,
    dataset_sha256: String,
    comparator_count: usize,
    sample_count: usize,
    replay_command: String,
}

#[derive(Debug, Clone, PartialEq, Eq)]
#[allow(clippy::struct_field_names)]
struct ArtifactBundle {
    manifest_path: PathBuf,
    matrix_path: PathBuf,
    samples_path: PathBuf,
}

fn fixture_dir() -> PathBuf {
    Path::new(env!("CARGO_MANIFEST_DIR")).join("tests/fixtures/benchmark_golden")
}

fn build_baseline_matrix(dataset_profile: &str) -> BenchmarkMatrix {
    BenchmarkMatrix {
        schema_version: ARTIFACT_SCHEMA_VERSION.to_owned(),
        matrix_version: MATRIX_VERSION.to_owned(),
        cases: vec![
            BenchmarkCase {
                path: BenchmarkPath::Crawl,
                dataset_profile: dataset_profile.to_owned(),
                warmup_iterations: 3,
                measured_iterations: 30,
            },
            BenchmarkCase {
                path: BenchmarkPath::Index,
                dataset_profile: dataset_profile.to_owned(),
                warmup_iterations: 3,
                measured_iterations: 25,
            },
            BenchmarkCase {
                path: BenchmarkPath::Query,
                dataset_profile: dataset_profile.to_owned(),
                warmup_iterations: 5,
                measured_iterations: 50,
            },
            BenchmarkCase {
                path: BenchmarkPath::Tui,
                dataset_profile: dataset_profile.to_owned(),
                warmup_iterations: 5,
                measured_iterations: 60,
            },
        ],
        comparators: vec![
            ComparatorDefinition {
                path: BenchmarkPath::Crawl,
                metric: ComparatorMetric::P95LatencyMs,
                baseline_key: "baseline_p95_ms.crawl".to_owned(),
                max_regression_pct: 20.0,
            },
            ComparatorDefinition {
                path: BenchmarkPath::Index,
                metric: ComparatorMetric::ThroughputPerSecond,
                baseline_key: "workload.index_documents".to_owned(),
                max_regression_pct: 15.0,
            },
            ComparatorDefinition {
                path: BenchmarkPath::Query,
                metric: ComparatorMetric::P95LatencyMs,
                baseline_key: "baseline_p95_ms.query".to_owned(),
                max_regression_pct: 10.0,
            },
            ComparatorDefinition {
                path: BenchmarkPath::Tui,
                metric: ComparatorMetric::FrameBudgetMs,
                baseline_key: "baseline_p95_ms.tui_frame".to_owned(),
                max_regression_pct: 5.0,
            },
        ],
    }
}

fn load_golden_dataset(profile: &str) -> GoldenDataset {
    let path = fixture_dir().join(format!("{profile}.json"));
    let raw = fs::read_to_string(&path).expect("read golden dataset fixture");
    serde_json::from_str::<GoldenDataset>(&raw).expect("parse golden dataset fixture")
}

fn sha256_hex_for_file(path: &Path) -> String {
    let output = Command::new("sha256sum")
        .arg(path)
        .output()
        .expect("invoke sha256sum");
    assert!(output.status.success(), "sha256sum command failed");
    let stdout = String::from_utf8(output.stdout).expect("decode sha256sum output");
    stdout
        .split_whitespace()
        .next()
        .expect("parse sha256sum digest")
        .to_owned()
}

fn sample_payload(case: &BenchmarkCase, dataset: &GoldenDataset) -> serde_json::Value {
    let comparator_value = match case.path {
        BenchmarkPath::Crawl => dataset.baseline_p95_ms.crawl,
        BenchmarkPath::Index => dataset.baseline_p95_ms.index,
        BenchmarkPath::Query => dataset.baseline_p95_ms.query,
        BenchmarkPath::Tui => dataset.baseline_p95_ms.tui_frame,
    };

    serde_json::json!({
        "path": case.path,
        "dataset_profile": case.dataset_profile,
        "warmup_iterations": case.warmup_iterations,
        "measured_iterations": case.measured_iterations,
        "comparator_value": comparator_value,
    })
}

fn write_artifact_bundle(
    out_dir: &Path,
    matrix: &BenchmarkMatrix,
    dataset: &GoldenDataset,
) -> ArtifactBundle {
    fs::create_dir_all(out_dir).expect("create artifact output dir");

    let dataset_path = fixture_dir().join(format!("{}.json", dataset.profile));
    let dataset_sha256 = sha256_hex_for_file(&dataset_path);

    let manifest = BenchmarkArtifactManifest {
        schema_version: ARTIFACT_SCHEMA_VERSION.to_owned(),
        matrix_version: matrix.matrix_version.clone(),
        dataset_profile: dataset.profile.clone(),
        dataset_version: dataset.dataset_version.clone(),
        dataset_sha256,
        comparator_count: matrix.comparators.len(),
        sample_count: matrix.cases.len(),
        replay_command:
            "cargo test -p frankensearch-fsfs --test benchmark_baseline_matrix -- --nocapture"
                .to_string(),
    };

    let manifest_path = out_dir.join("benchmark_manifest.json");
    let matrix_path = out_dir.join("benchmark_matrix.json");
    let samples_path = out_dir.join("samples.jsonl");

    fs::write(
        &manifest_path,
        serde_json::to_vec_pretty(&manifest).expect("serialize manifest"),
    )
    .expect("write manifest artifact");
    fs::write(
        &matrix_path,
        serde_json::to_vec_pretty(matrix).expect("serialize matrix"),
    )
    .expect("write matrix artifact");

    let mut samples = fs::File::create(&samples_path).expect("create samples artifact");
    for case in &matrix.cases {
        let payload = sample_payload(case, dataset);
        let encoded = serde_json::to_string(&payload).expect("encode sample line");
        writeln!(samples, "{encoded}").expect("write sample line");
    }

    ArtifactBundle {
        manifest_path,
        matrix_path,
        samples_path,
    }
}

#[test]
fn benchmark_matrix_covers_crawl_index_query_tui_paths() {
    let matrix = build_baseline_matrix("small");
    let covered: BTreeSet<_> = matrix.cases.iter().map(|case| case.path).collect();

    assert_eq!(matrix.schema_version, ARTIFACT_SCHEMA_VERSION);
    assert_eq!(matrix.matrix_version, MATRIX_VERSION);
    assert_eq!(matrix.cases.len(), 4);
    assert_eq!(matrix.comparators.len(), 4);

    let expected = BTreeSet::from([
        BenchmarkPath::Crawl,
        BenchmarkPath::Index,
        BenchmarkPath::Query,
        BenchmarkPath::Tui,
    ]);
    assert_eq!(covered, expected);
}

#[test]
fn golden_datasets_are_versioned_and_reproducible() {
    let expected_hashes = [
        (
            "tiny",
            "e99b242723daa36cbae9512b725abd8965cdf85390a161eb5dfcc54e91595638",
        ),
        (
            "small",
            "6f87f4fc3779f67ff6d595fe8733a4c9ee8541f224724ac788d08b9416bef759",
        ),
        (
            "medium",
            "34926c4b04cca3f9c3eed8c7c483a81c9cebaff93b48b28c3eab6ab0096ac27d",
        ),
    ];

    for (profile, expected_hash) in expected_hashes {
        let fixture_path = fixture_dir().join(format!("{profile}.json"));
        let raw = fs::read(&fixture_path).expect("read fixture bytes");
        let digest = sha256_hex_for_file(&fixture_path);

        let dataset: GoldenDataset =
            serde_json::from_slice(&raw).expect("parse golden dataset fixture");
        assert_eq!(dataset.schema_version, GOLDEN_SCHEMA_VERSION);
        assert_eq!(dataset.dataset_version, "2026-02-14");
        assert_eq!(dataset.profile, profile);
        assert_eq!(digest, expected_hash);
    }

    assert_eq!(GOLDEN_PROFILES.len(), 3);
}

#[test]
fn artifact_capture_supports_later_statistical_comparison() {
    let matrix = build_baseline_matrix("small");
    let dataset = load_golden_dataset("small");
    let temp = TempDir::new().expect("create temp dir");

    let bundle = write_artifact_bundle(temp.path(), &matrix, &dataset);

    assert!(bundle.manifest_path.exists());
    assert!(bundle.matrix_path.exists());
    assert!(bundle.samples_path.exists());

    let manifest_raw = fs::read_to_string(&bundle.manifest_path).expect("read manifest");
    let manifest: BenchmarkArtifactManifest =
        serde_json::from_str(&manifest_raw).expect("parse manifest");

    assert_eq!(manifest.schema_version, ARTIFACT_SCHEMA_VERSION);
    assert_eq!(manifest.matrix_version, MATRIX_VERSION);
    assert_eq!(manifest.dataset_profile, "small");
    assert_eq!(manifest.dataset_version, "2026-02-14");
    assert_eq!(manifest.comparator_count, 4);
    assert_eq!(manifest.sample_count, 4);
    assert!(
        manifest
            .replay_command
            .contains("benchmark_baseline_matrix")
    );

    let sample_lines = fs::read_to_string(&bundle.samples_path).expect("read samples");
    let non_empty_count = sample_lines.lines().filter(|line| !line.is_empty()).count();
    assert_eq!(non_empty_count, 4);
}
